import os
import pandas as pd
import torch
from PIL import Image
from transformers import AutoModelForCausalLM
import gc

model = AutoModelForCausalLM.from_pretrained(
    "AIDC-AI/Ovis2-4B",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    multimodel_max_lenght=32768,
).cuda()

text_tokenizer = model.get_text_tokenizer()
visual_tokenizer = model.get_visual_tokenizer()

output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

# è®€å–åœ–ç‰‡
image_dir = "images"
image_files = [f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')]

all_data = []

# åŸ·è¡Œè¾¨è­˜
for image_name in image_files:
    image_path = os.path.join(image_dir, image_name)
    image = Image.open(image_path).convert("RGB").resize((960,960))
    images = [image]

    # è¨­å®šæç¤ºè©èˆ‡åœ–ç‰‡æ•¸
    max_partition = 3
    text_prompt = "è«‹è¾¨è­˜åœ–ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—ï¼Œåˆ—å‡ºå®Œæ•´æ¸…å–®ã€‚"
    query = "<image>\n" + text_prompt

    # å‰è™•ç†
    prompt, input_ids, pixel_values = model.preprocess_inputs(query, images, max_partition=max_partition)
    attention_mask = torch.ne(input_ids, text_tokenizer.pad_token_id)
    input_ids = input_ids.unsqueeze(0).to(model.device)
    attention_mask = attention_mask.unsqueeze(0).to(model.device)
    pixel_values = pixel_values.to(dtype=visual_tokenizer.dtype, device=visual_tokenizer.device)
    pixel_values = [pixel_values]

    # æ¨è«–
        # æ¨è«–
    # ç”Ÿæˆ output_ids
    with torch.inference_mode():
        output_ids = model.generate(
            input_ids,
            pixel_values=pixel_values,
            attention_mask=attention_mask,
            max_new_tokens=1024,
            do_sample=False,
            eos_token_id=model.generation_config.eos_token_id,
            pad_token_id=text_tokenizer.pad_token_id,
        )[0]

    # è§£æ output_ids æˆ output_text
    output_text = text_tokenizer.decode(output_ids, skip_special_tokens=True)
    print(f"\nğŸ“„ {image_name} è¾¨è­˜çµæœï¼š\n{output_text}\n")
    
    # æ¸…é™¤è³‡æºï¼ˆé€™è¡Œå¿…é ˆåœ¨ decode ä¹‹å¾Œï¼‰
    del input_ids, attention_mask, pixel_values, output_ids
    torch.cuda.empty_cache()
    gc.collect()
    

    # å°‡çµæœæŒ‰è¡Œåˆ†å‰²ä¸¦è¨˜éŒ„
    lines = [line.strip() for line in output_text.split('\n') if line.strip()]
    df = pd.DataFrame(lines, columns=["Text"])
        
    output_path = os.path.join(output_dir, f"{os.path.splitext(image_name)[0]}.csv")
    df.to_csv(output_path, index=False, encoding="utf-8-sig")
print("âœ… å·²å°‡å„å¼µåœ–ç‰‡è¾¨è­˜çµæœåˆ†åˆ¥è¼¸å‡ºè‡³ output è³‡æ–™å¤¾ä¸­ã€‚")
